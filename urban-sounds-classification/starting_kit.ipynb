{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "###  Challenge SD207 - 2017\n",
    "#### Authors :  Umut Şimşekli & Slim Essid & Victor Bisot\n",
    "\n",
    "\n",
    "In this challenge, your task is to do **\"acoustic scene classification\"**. In particular, given an audio signal of ~30 seconds, the goal is to find its \"context\" or the \"environment\" corresponding to the signal. These enviroments can be very different such as a beach, a restaurant, or a metro station. In total we will consider 15 different classes, which are listed below.  \n",
    "\n",
    "Here, we provide a dataset of audio files which can be find under **/tsi/plato/sons/sd207**. The dataset is split into 3 parts: (1) training, (2) validation, and (3) test. \n",
    "\n",
    "The audio files that are in the **training** set (and their labels) are indicated in **train.txt**. \n",
    "\n",
    "The audio files that are in the **validation** set (and their labels) are indicated in **dev.txt**. \n",
    "\n",
    "Finally, the audio files that are in the **test** set can be downloaded from this link:\n",
    "https://www.dropbox.com/s/rtqr6m718xdvwv3/test_files.txt\n",
    "\n",
    "The labels of the test files are not provided.\n",
    "\n",
    "\n",
    "#### The classes and their indices are given as follows:\n",
    "\n",
    "0: beach \n",
    "\n",
    "1: bus\n",
    "\n",
    "2: cafe/restaurant\n",
    "\n",
    "3: car\n",
    "\n",
    "4: city_center\n",
    "\n",
    "5: forest_path\n",
    "\n",
    "6: grocery_store\n",
    "\n",
    "7: home\n",
    "\n",
    "8: library\n",
    "\n",
    "9: metro_station\n",
    "\n",
    "10: office\n",
    "\n",
    "11: park\n",
    "\n",
    "12: residential_area\n",
    "\n",
    "13: train\n",
    "\n",
    "14: tram\n",
    "\n",
    "\n",
    "# Approach\n",
    "\n",
    "For processing audio files, you can use the library called \"librosa\". This library is already installed in your computers. However, make sure that you use the correct python version:\n",
    "\n",
    "**/cal/softs/anaconda/anaconda-2.0.1.20160115/bin**\n",
    "\n",
    "During the inital lecture, we will show you the basic principles of audio processing (which is not complicated! :) ) and then you will develop your own system for acoustic scene classification.  \n",
    "\n",
    "Here, you can find some information about librosa and audio processing:\n",
    "https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "The score will be simply the **accuracy** of your classification algorithm:\n",
    "\n",
    "$100 \\times \\frac1{N}\\sum_{i=1}^N \\mathbb{1} (y_i = \\hat{y}_i) $,\n",
    "\n",
    "where $N$ denotes the number of test instances, $y_i$ denotes the true test labels and $\\hat{y}_i$ denotes the estimation of your algorithm.\n",
    "\n",
    "\n",
    "\n",
    "# The Rules and the Deadline\n",
    "\n",
    "**You can work in groups of 2. **\n",
    "\n",
    "The deadline is **June 25 2017, 23:59**.\n",
    "\n",
    "**You also need to submit a ~3 pages report for the challenge in pdf or as an ipython notebook.**\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
